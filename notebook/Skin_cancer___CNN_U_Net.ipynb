{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 - Business Problem\n",
        "\n",
        "**Business Problem: AI-Assisted Diagnosis of Skin Cancer Using Deep Learning**\n",
        "\n",
        "### Context\n",
        "\n",
        "Skin cancer is one of the most common types of cancer, and early diagnosis is essential to increase the chances of a cure. Dermatoscopic examination requires specialized knowledge and can be subject to inter-observer variability. The use of artificial intelligence—especially convolutional neural networks (CNNs)—can **assist dermatologists** in detecting, classifying, and outlining suspicious skin lesions.\n",
        "\n",
        "### Business Objective\n",
        "\n",
        "**Develop an automated system based on Deep Learning that:**\n",
        "\n",
        "1. **Classifies** images of skin lesions into different types (benign, melanoma, etc.).\n",
        "\n",
        "2. **Automatically segments** the lesion area in the image, highlighting the suspicious region.\n",
        "\n",
        "### Rationale / Added Value\n",
        "\n",
        "* **Increased accuracy** in diagnosis, reducing false negatives and false positives.\n",
        "\n",
        "* **Standardization** of medical reports, minimizing subjectivity.\n",
        "\n",
        "* **Remote assistance** in regions with few dermatologists.\n",
        "\n",
        "* **Faster** patient screening and care.\n",
        "\n",
        "### Problem Formulation\n",
        "\n",
        "**Problem 1: Classification**\n",
        "\n",
        "* Given an image of a skin lesion, the model should assign it to one of the possible classes (melanoma, basal cell carcinoma, nevus, etc.).\n",
        "\n",
        "* **Suggested metrics:** Accuracy, F1-score (to handle class imbalance).\n",
        "\n",
        "**Problem 2: Segmentation**\n",
        "\n",
        "* Given an image, the model should generate a **binary mask** indicating the exact area of the lesion.\n",
        "\n",
        "* **Suggested metrics:** IoU (Intersection over Union), Dice Coefficient.\n",
        "\n",
        "## Technical Approach\n",
        "\n",
        "### Classification with CNNs\n",
        "\n",
        "* Use standard architectures such as **ResNet, EfficientNet, VGG**, or custom models.\n",
        "\n",
        "* Train the model to differentiate between types of skin lesions.\n",
        "\n",
        "### Segmentation with U-Net\n",
        "\n",
        "* U-Net is a CNN architecture designed for medical image segmentation.\n",
        "\n",
        "* It enables the generation of a precise mask of the lesion area.\n",
        "\n",
        "* This is essential for indicating the region of interest to clinicians, and can be combined with the classification output for greater reliability.\n",
        "\n",
        "#### Example Pipeline\n",
        "\n",
        "1. **Preprocessing:** Normalization, resizing, data augmentation.\n",
        "\n",
        "2. **Training U-Net:** Image as input, mask as output.\n",
        "\n",
        "3. **Evaluation:** Metrics such as Dice, IoU.\n",
        "\n",
        "4. **Visualization:** Overlay the segmented mask on the original image.\n",
        "\n",
        "## Example Problem Statement\n",
        "\n",
        "> **\"How can we use convolutional neural networks to automate the classification and segmentation of skin lesions, assisting dermatologists in the early diagnosis of skin cancer?\"**\n",
        "\n",
        "## Possible Extensions\n",
        "\n",
        "* Automated medical reports (including lesion type and area).\n",
        "\n",
        "* Embedded systems for clinics and doctor’s offices.\n",
        "\n",
        "* Telemedicine triage platforms.\n",
        "\n",
        "## Real-World Applications (References)\n",
        "\n",
        "* [Google Health Skin AI](https://www.blog.google/technology/health/dermatology-ai-preview/)\n",
        "\n",
        "* [Nature Medicine 2020 Study](https://www.nature.com/articles/s41591-020-0942-0) (same research group as your dataset)\n",
        "\n",
        "## How to Use in Your Presentation/Proposal\n",
        "\n",
        "You can start with a real-world context (case statistics, diagnostic challenges), present the dataset, explain the tasks, and propose a solution based on CNN/U-Net, demonstrating real impact in healthcare."
      ],
      "metadata": {
        "id": "YRJRrCQEZOoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2 - API Kaggle**"
      ],
      "metadata": {
        "id": "cXOgtE1z08tg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFXc-JwKzfRS"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "id": "gbhTMzkOzpVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "Gu-2UA7OzsKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "o6OrFHEOzsRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "oxvTJg1yzz0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading database from kaggle\n",
        "!kaggle datasets download surajghuwalewala/ham1000-segmentation-and-classification"
      ],
      "metadata": {
        "id": "UZeIT-eM0Kyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3 - Baixando dataset"
      ],
      "metadata": {
        "id": "KGsPapFy042O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the zip file containing the Bitcoin tweets dataset\n",
        "zf = \"/content/ham1000-segmentation-and-classification.zip\""
      ],
      "metadata": {
        "id": "E520ii7l0XHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target directory where the dataset will be extracted\n",
        "target_dir = \"/content/dataset/CNN/skin\""
      ],
      "metadata": {
        "id": "hoCyjt-V0YjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the zip file containing the dataset\n",
        "zfile = zipfile.ZipFile(zf)"
      ],
      "metadata": {
        "id": "muh4RiwB0ZrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all contents of the zip file to the target directory\n",
        "zfile.extractall(target_dir)"
      ],
      "metadata": {
        "id": "NvQoGo-00bZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4 - Importando as bibliotecas"
      ],
      "metadata": {
        "id": "1BPc_ODO012r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##\n",
        "\n",
        "#\n",
        "import os\n",
        "\n",
        "#\n",
        "import numpy as np\n",
        "\n",
        "#\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#\n",
        "from PIL import Image\n",
        "\n",
        "#\n",
        "from glob import glob\n",
        "\n",
        "#\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Dropout\n",
        "\n",
        "#\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "#\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "#\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "09kBGsxC01NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho dos dados\n",
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 7  # Troque pelo número de classes do seu problema"
      ],
      "metadata": {
        "id": "T8s0d1isaImJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 5 - Database**"
      ],
      "metadata": {
        "id": "VRMLnIQTajfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista dos caminhos completos das imagens e máscaras\n",
        "image_paths = sorted(glob('/content/dataset/CNN/skin/images/*.jpg'))  # ou .png, ajuste se necessário\n",
        "mask_paths = sorted(glob('/content/dataset/CNN/skin/masks/*.png'))    # geralmente máscara é PNG\n",
        "\n",
        "print(f\"Total de imagens: {len(image_paths)}\")\n",
        "print(f\"Total de máscaras: {len(mask_paths)}\")"
      ],
      "metadata": {
        "id": "6Z5dWRoXaphu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, val_images, train_masks, val_masks = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "2jchCfjSatXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 6 - Data Generator**"
      ],
      "metadata": {
        "id": "risn-gThaL_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, image_filenames, mask_filenames, batch_size=16, img_size=IMG_SIZE):\n",
        "        self.image_filenames = image_filenames\n",
        "        self.mask_filenames = mask_filenames\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_img = self.image_filenames[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        batch_mask = self.mask_filenames[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "\n",
        "        X = np.zeros((len(batch_img), *self.img_size, 3), dtype=np.float32)\n",
        "        y = np.zeros((len(batch_mask), *self.img_size, 1), dtype=np.float32)\n",
        "\n",
        "        for i, (img_path, mask_path) in enumerate(zip(batch_img, batch_mask)):\n",
        "            img = Image.open(img_path).resize(self.img_size)\n",
        "            img = np.array(img) / 255.0\n",
        "            if img.ndim == 2:\n",
        "                img = np.stack([img]*3, axis=-1)\n",
        "            X[i] = img\n",
        "\n",
        "            mask = Image.open(mask_path).resize(self.img_size)\n",
        "            mask = np.array(mask)\n",
        "            if mask.ndim == 3:\n",
        "                mask = mask[..., 0]  # se máscara for RGB, pega canal 0\n",
        "            mask = np.expand_dims(mask, axis=-1) / 255.0\n",
        "            y[i] = mask\n",
        "\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "R3tb_N4XaIpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 7 - Generators**"
      ],
      "metadata": {
        "id": "PAm0uKB9a39t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "#\n",
        "train_gen = DataGenerator(train_images, train_masks, batch_size=BATCH_SIZE)\n",
        "\n",
        "#\n",
        "val_gen = DataGenerator(val_images, val_masks, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "Xc9KOlnZaIsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 8 - Rede Neural 1 U-Net**"
      ],
      "metadata": {
        "id": "V4EODcNxa_VO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet(input_shape=(128, 128, 3)):\n",
        "    inputs = Input(input_shape)\n",
        "    # Encoder\n",
        "    c1 = Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
        "    p1 = MaxPooling2D()(c1)\n",
        "    c2 = Conv2D(32, 3, activation='relu', padding='same')(p1)\n",
        "    p2 = MaxPooling2D()(c2)\n",
        "    c3 = Conv2D(64, 3, activation='relu', padding='same')(p2)\n",
        "    p3 = MaxPooling2D()(c3)\n",
        "    # Bottleneck\n",
        "    b = Conv2D(128, 3, activation='relu', padding='same')(p3)\n",
        "    # Decoder\n",
        "    u1 = Conv2DTranspose(64, 2, strides=2, padding='same')(b)\n",
        "    u1 = concatenate([u1, c3])\n",
        "    u2 = Conv2DTranspose(32, 2, strides=2, padding='same')(u1)\n",
        "    u2 = concatenate([u2, c2])\n",
        "    u3 = Conv2DTranspose(16, 2, strides=2, padding='same')(u2)\n",
        "    u3 = concatenate([u3, c1])\n",
        "    outputs = Conv2D(1, 1, activation='sigmoid')(u3)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(tf.round(y_pred))  # arredonda p/ binário\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(tf.round(y_pred))  # arredonda p/ binário\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "unet = build_unet()\n",
        "unet.compile(optimizer='adam',\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy', iou_coef, dice_coef])\n",
        "\n",
        "unet.summary()"
      ],
      "metadata": {
        "id": "2WlqhzZsaIvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "#\n",
        "history = unet.fit(train_gen,\n",
        "                   validation_data=val_gen,\n",
        "                   epochs=5)"
      ],
      "metadata": {
        "id": "SYgeJjfubMOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para plotar o desempenho\n",
        "def plot_training_history(history):\n",
        "    # Loss\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title('Loss over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(False)\n",
        "\n",
        "    # Accuracy (funciona para accuracy, IoU, Dice... se estiver no metrics do modelo)\n",
        "    if 'accuracy' in history.history:\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "        plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "        plt.title('Accuracy over Epochs')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.grid(False)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Chame a função após o treino\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "dfAA7TFDbRDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc, val_iou, val_dice = unet.evaluate(val_gen)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['iou_coef'], label='Train IoU')\n",
        "plt.plot(history.history['val_iou_coef'], label='Val IoU')\n",
        "plt.title('IoU over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['dice_coef'], label='Train Dice')\n",
        "plt.plot(history.history['val_dice_coef'], label='Val Dice')\n",
        "plt.title('Dice Coefficient over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Dice')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Val Loss: {val_loss:.4f}\")\n",
        "print(f\"Val Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Val IoU: {val_iou:.4f}\")\n",
        "print(f\"Val Dice: {val_dice:.4f}\")"
      ],
      "metadata": {
        "id": "PxoBmAw6cAPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 9 - Avaliação métricas do CNN 1 U-Net**"
      ],
      "metadata": {
        "id": "jKBqKBNBcszc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegue um batch do seu generator (ou use X_val e y_val arrays)\n",
        "X_val, y_val = val_gen[0]  # primeiro batch de validação\n",
        "y_pred = unet.predict(X_val)\n",
        "\n",
        "# Binarize as máscaras preditas\n",
        "y_pred_bin = (y_pred > 0.5).astype(np.uint8)\n",
        "y_true_bin = (y_val > 0.5).astype(np.uint8)\n",
        "\n",
        "\n",
        "# Transforme as máscaras em vetores 1D (para cada pixel ser uma \"amostra\")\n",
        "y_true_flat = y_true_bin.flatten()\n",
        "y_pred_flat = y_pred_bin.flatten()"
      ],
      "metadata": {
        "id": "YUR95axJcL_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification report U-Net\n",
        "report = classification_report(y_true_flat, y_pred_flat, target_names=['Background', 'Lesion'])\n",
        "print(report)"
      ],
      "metadata": {
        "id": "ue-NfvtlcP67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gere as previsões e binarize\n",
        "# X_val, y_val = val_gen[0]\n",
        "# y_pred = unet.predict(X_val)\n",
        "\n",
        "y_pred_bin = (y_pred > 0.5).astype(np.uint8)\n",
        "y_true_bin = (y_val > 0.5).astype(np.uint8)\n",
        "\n",
        "# Transforme em vetores 1D\n",
        "y_true_flat = y_true_bin.flatten()\n",
        "y_pred_flat = y_pred_bin.flatten()"
      ],
      "metadata": {
        "id": "UVFtTwXlccyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gere a matriz de confusão e visualize\n",
        "\n",
        "cm = confusion_matrix(y_true_flat, y_pred_flat)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Background', 'Lesion'])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix (per pixel)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cyeA_5oscjEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 10 - Previsão das imagens Rede Neural 1 - U-Net**"
      ],
      "metadata": {
        "id": "mvuYJkU-c03j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando imagens e máscaras do val_gen (validação)\n",
        "# Pegue um batch do generator de validação\n",
        "\n",
        "# Pode mudar o índice para ver outros batches\n",
        "X_val, y_val = val_gen[0]"
      ],
      "metadata": {
        "id": "MO3hzHaCdBg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Faça a predição\n",
        "# Realize a predição (output entre 0 e 1)\n",
        "y_pred = unet.predict(X_val)"
      ],
      "metadata": {
        "id": "2zgnEwBCd5zE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binarize a máscara predita\n",
        "# Limiares > 0.5 viram \"lesão\"\n",
        "y_pred_bin = (y_pred > 0.5).astype(np.uint8)"
      ],
      "metadata": {
        "id": "NbsuBwbtd57Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualize o resultado (imagem, ground truth, predição)\n",
        "\n",
        "n = 5  # número de exemplos para mostrar\n",
        "plt.figure(figsize=(12, n*3))\n",
        "\n",
        "for i in range(n):\n",
        "    plt.subplot(n, 3, i*3 + 1)\n",
        "    plt.imshow(X_val[i])\n",
        "    plt.title('Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(n, 3, i*3 + 2)\n",
        "    plt.imshow(y_val[i].squeeze(), cmap='gray')\n",
        "    plt.title('Ground Truth')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(n, 3, i*3 + 3)\n",
        "    plt.imshow(y_pred_bin[i].squeeze(), cmap='gray')\n",
        "    plt.title('Prediction')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "up3o3TCmeAtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Fazer previsão em uma nova imagem (fora do dataset)\n",
        "\n",
        "# Previsão em uma imagem específica (ex: img_path = \"/content/my_image.jpg\")\n",
        "\n",
        "#\n",
        "def predict_single_image(model, img_path, img_size=(128, 128)):\n",
        "    img = Image.open(img_path).resize(img_size)\n",
        "    img = np.array(img) / 255.0\n",
        "    if img.ndim == 2:  # grayscale\n",
        "        img = np.stack([img]*3, axis=-1)\n",
        "    img = np.expand_dims(img, axis=0)  # (1, h, w, 3)\n",
        "    pred = model.predict(img)\n",
        "    mask_pred = (pred[0, :, :, 0] > 0.5).astype(np.uint8)\n",
        "    return img[0], mask_pred"
      ],
      "metadata": {
        "id": "q4G7S5WReFb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##\n",
        "# Exemplo de uso\n",
        "\n",
        "#\n",
        "img_path = \"/content/dataset/CNN/skin/images/ISIC_0024306.jpg\"\n",
        "\n",
        "#\n",
        "img, mask_pred = predict_single_image(unet, img_path)"
      ],
      "metadata": {
        "id": "vBWU5IsteLEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(mask_pred, cmap='gray')\n",
        "plt.title(\"Predicted Mask\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X3caY8MXeQEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 11 - Salvando rede neural 1 U-Net**"
      ],
      "metadata": {
        "id": "zQB4qV07eTib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Salvar o modelo completo (.h5 ou SavedModel)\n",
        "# Forma clássica: salva tudo em único arquivo\n",
        "unet.save('/content/unet_skin_segmentation.h5')\n",
        "\n",
        "# Forma moderna: salva em formato \"SavedModel\" (pasta)\n",
        "#unet.save('/content/unet_skin_segmentation_model')"
      ],
      "metadata": {
        "id": "fqQSsJ-meYbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Salvar apenas os pesos (caso queira restaurar numa arquitetura igual)\n",
        "\n",
        "# Salva só os pesos\n",
        "#unet.save_weights('/content/unet_weights.h5')"
      ],
      "metadata": {
        "id": "kdC7EM_aeh4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 12 - Rede Neural 2 - U-Net VGG16**"
      ],
      "metadata": {
        "id": "fsS4NEMbkWsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_with_vgg16_encoder(input_shape=(128, 128, 3), freeze_encoder=True):\n",
        "    # Carrega VGG16 pré-treinado sem o topo\n",
        "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    if freeze_encoder:\n",
        "        vgg16.trainable = False\n",
        "\n",
        "    # Encoder (skip connections)\n",
        "    inputs = vgg16.input\n",
        "    s1 = vgg16.get_layer('block1_conv2').output  # (128, 128, 64)\n",
        "    s2 = vgg16.get_layer('block2_conv2').output  # (64, 64, 128)\n",
        "    s3 = vgg16.get_layer('block3_conv3').output  # (32, 32, 256)\n",
        "    s4 = vgg16.get_layer('block4_conv3').output  # (16, 16, 512)\n",
        "    b = vgg16.get_layer('block5_conv3').output   # (8, 8, 512)\n",
        "\n",
        "    # Decoder\n",
        "    d1 = Conv2DTranspose(512, 2, strides=2, padding='same')(b)    # (16, 16, 512)\n",
        "    d1 = concatenate([d1, s4])\n",
        "    d1 = Conv2D(512, 3, activation='relu', padding='same')(d1)\n",
        "    d1 = Conv2D(512, 3, activation='relu', padding='same')(d1)\n",
        "\n",
        "    d2 = Conv2DTranspose(256, 2, strides=2, padding='same')(d1)   # (32, 32, 256)\n",
        "    d2 = concatenate([d2, s3])\n",
        "    d2 = Conv2D(256, 3, activation='relu', padding='same')(d2)\n",
        "    d2 = Conv2D(256, 3, activation='relu', padding='same')(d2)\n",
        "\n",
        "    d3 = Conv2DTranspose(128, 2, strides=2, padding='same')(d2)   # (64, 64, 128)\n",
        "    d3 = concatenate([d3, s2])\n",
        "    d3 = Conv2D(128, 3, activation='relu', padding='same')(d3)\n",
        "    d3 = Conv2D(128, 3, activation='relu', padding='same')(d3)\n",
        "\n",
        "    d4 = Conv2DTranspose(64, 2, strides=2, padding='same')(d3)    # (128, 128, 64)\n",
        "    d4 = concatenate([d4, s1])\n",
        "    d4 = Conv2D(64, 3, activation='relu', padding='same')(d4)\n",
        "    d4 = Conv2D(64, 3, activation='relu', padding='same')(d4)\n",
        "\n",
        "    # Saída (1 canal, para máscara binária)\n",
        "    outputs = Conv2D(1, 1, activation='sigmoid', padding='same')(d4)\n",
        "\n",
        "    model2 = Model(inputs, outputs)\n",
        "    return model2\n",
        "\n",
        "# Criando o modelo\n",
        "input_shape = (128, 128, 3)\n",
        "model2 = unet_with_vgg16_encoder(input_shape=input_shape, freeze_encoder=True)\n",
        "\n",
        "#\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(tf.round(y_pred))\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "#\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(tf.round(y_pred))\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "#\n",
        "model2.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', iou_coef, dice_coef])\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "3XJuGX7LkhRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supondo que você já tenha train_gen e val_gen prontos\n",
        "history2 = model2.fit(train_gen,\n",
        "                      validation_data=val_gen,\n",
        "                      epochs=5)"
      ],
      "metadata": {
        "id": "c58cbK6BknVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(history2.history.keys())\n"
      ],
      "metadata": {
        "id": "W4EZyVqRqbje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    metrics = [m for m in history.history.keys() if not m.startswith('val_')]\n",
        "    n_metrics = len(metrics)\n",
        "\n",
        "    plt.figure(figsize=(6 * n_metrics, 5))\n",
        "    for i, metric in enumerate(metrics):\n",
        "        plt.subplot(1, n_metrics, i+1)\n",
        "        plt.plot(history.history[metric], label='Train ' + metric)\n",
        "        if f'val_{metric}' in history.history:\n",
        "            plt.plot(history.history[f'val_{metric}'], label='Val ' + metric)\n",
        "        plt.title(metric.capitalize())\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(metric)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Chame assim:\n",
        "plot_training_history(history2)"
      ],
      "metadata": {
        "id": "h-pWdEbvqIw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apenas Loss\n",
        "plt.plot(history2.history['loss'], label='Train Loss')\n",
        "plt.plot(history2.history['val_loss'], label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5WA-8QqEqI4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 13 - Metricas e avaliação 2**"
      ],
      "metadata": {
        "id": "jpLV8sqHrp6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegue um batch do generator de validação\n",
        "X_val, y_val = val_gen[0]   # Use outros índices para mais imagens\n",
        "\n",
        "# Gere as previsões\n",
        "y_pred = model2.predict(X_val)\n",
        "\n",
        "# Binarize as máscaras preditas (> 0.5 vira 1)\n",
        "y_pred_bin = (y_pred > 0.5).astype(np.uint8)\n",
        "y_true_bin = (y_val > 0.5).astype(np.uint8)"
      ],
      "metadata": {
        "id": "jX11ftgyqI8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten para comparar pixel a pixel\n",
        "y_true_flat = y_true_bin.flatten()\n",
        "y_pred_flat = y_pred_bin.flatten()"
      ],
      "metadata": {
        "id": "y60Kz8l0qnxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "print(classification_report(\n",
        "    y_true_flat, y_pred_flat, target_names=['Background', 'Lesion']\n",
        "))"
      ],
      "metadata": {
        "id": "oFZtU1m3qqmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de Confusão\n",
        "cm = confusion_matrix(y_true_flat, y_pred_flat)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Background', 'Lesion'])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix (per pixel)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "scYz-I1equn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 14 - Previsãoes imagens**"
      ],
      "metadata": {
        "id": "ub35RRudryEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo para várias batches (opcional)\n",
        "y_true_all, y_pred_all = [], []\n",
        "for i in range(len(val_gen)):\n",
        "\n",
        "    X_batch, y_batch = val_gen[i]\n",
        "    pred_batch = model2.predict(X_batch)\n",
        "    y_true_all.append(y_batch)\n",
        "    y_pred_all.append(pred_batch)\n",
        "\n",
        "y_true_all = np.concatenate(y_true_all, axis=0)\n",
        "y_pred_all = np.concatenate(y_pred_all, axis=0)\n",
        "y_true_flat = (y_true_all > 0.5).astype(np.uint8).flatten()\n",
        "y_pred_flat = (y_pred_all > 0.5).astype(np.uint8).flatten()"
      ],
      "metadata": {
        "id": "KBUIuEFZqynK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização de Previsões\n",
        "X_val, y_val = val_gen[0]\n",
        "y_pred = model2.predict(X_val)\n",
        "y_pred_bin = (y_pred > 0.5).astype(np.uint8)"
      ],
      "metadata": {
        "id": "LMzO6GFxkw4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5\n",
        "\n",
        "plt.figure(figsize=(12, n*3))\n",
        "for i in range(n):\n",
        "    plt.subplot(n, 3, i*3 + 1)\n",
        "    plt.imshow(X_val[i])\n",
        "    plt.title('Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(n, 3, i*3 + 2)\n",
        "    plt.imshow(y_val[i].squeeze(), cmap='gray')\n",
        "    plt.title('Ground Truth')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(n, 3, i*3 + 3)\n",
        "    plt.imshow(y_pred_bin[i].squeeze(), cmap='gray')\n",
        "    plt.title('Prediction')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LNh-mxs0ky7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single_image(model, img_path, img_size=(128,128)):\n",
        "    # Carrega e prepara a imagem\n",
        "    img = Image.open(img_path).resize(img_size)\n",
        "    img_array = np.array(img) / 255.0\n",
        "    if img_array.ndim == 2:  # Se for grayscale, converte para RGB\n",
        "        img_array = np.stack([img_array]*3, axis=-1)\n",
        "    img_input = np.expand_dims(img_array, axis=0)  # (1, h, w, 3)\n",
        "\n",
        "    # Faz predição\n",
        "    pred = model.predict(img_input)\n",
        "    mask_pred = (pred[0, :, :, 0] > 0.5).astype(np.uint8)\n",
        "    return img_array, mask_pred"
      ],
      "metadata": {
        "id": "iHPbO9qHq-tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso\n",
        "\n",
        "# Troque para o caminho da sua imagem!\n",
        "img_path = '/content/dataset/CNN/skin/images/ISIC_0024311.jpg'\n",
        "\n",
        "# Previsao modelo\n",
        "img, mask_pred = predict_single_image(model2, img_path)"
      ],
      "metadata": {
        "id": "XDPIIMHErPiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(mask_pred, cmap='gray')\n",
        "plt.title(\"Predicted Mask\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SS-wsn_erQCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 15 - Salvando Rede Neural 2 VGG16**"
      ],
      "metadata": {
        "id": "n6gXhdr7r4ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar em formato HDF5 (arquivo único)\n",
        "model2.save('/content/unet_vgg16_skin.h5')\n",
        "\n",
        "# Ou em formato SavedModel (pasta)\n",
        "#model2.save('/content/unet_vgg16_skin_model')\n",
        "\n",
        "#model2.save_weights('/content/unet_vgg16_skin_weights.h5')"
      ],
      "metadata": {
        "id": "DPGh6T3Qq1eu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}